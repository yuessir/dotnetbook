It seems like you haven't provided any text to translate. Could you please provide the text you want translated into Chinese?

# 内存操作优化实践

在我的优化实践中，我得出了一个有趣的，虽然合乎逻辑的结论。如果我们能消除GC（垃圾回收）的触发，应用程序会运行得更快。听起来就像是：“嗯，显然！谁会反对呢？”。然而，并不是每个人都能回答“快了多少”这个问题。

我的例子当然有些天真……但当我在处理Samba协议并重写了`SMBLibrary`库时，结果是在相同的代码结构下，但通过不同的内存操作方式，执行时间减少了`-41%`。想象一下：`41%`的时间花在了分配、GC和数据结构选择不优化上（包括因为数组是以常规方式分配的，而我们可以使用池化技术）。

当然，大部分时间和内存都花在了如`Dictionary`、`List`、`Queue`这类数据结构上，因为它们的填充没有预设`capacity`。此外，还有许多不必要地分配的数组。然而，用户定义类型的小对象的流量也占用了大量时间。

对象流量，至少会导致GC0。然而，如果流量密集，应用程序经常简直来不及释放引用和对象，而不是在GC0中清理内存，清理将发生在GC1中。我遇到的最糟糕情况是，流量非常密集且是多线程的。这导致对象以巨大的集群进入第二代。这会导致什么后果？GC将运行更长时间。也就是说，它需要分析更大的内存区域来理解哪些对象不再被引用。此外，如果这些对象被一些旧集合或旧对象（来自第二代世界）引用，那么卡表机制就会介入（你可以在Konrad Kokosa的.NET Memory Management中了解更多）。这意味着更大的分析开销。听起来不是很优化。但我们该怎么办？似乎很无望：毕竟，实体还是要分配的。而且，内存在这里是完全分配和释放的。然而，如果我们回想一下“实体生命周期”一章，我们会记得，实体的生命周期本质上是一个虚拟概念，更多地取决于*人的*感知。确切地说是人：因为事实上，内存分配根本不存在。取而代之的是对某种类型的物理内存的标记和人的理解，即从*这一刻起*可以使用对象。

[>]: 对我来说，短命对象掉入第二代的事实并不是一开始就很明显。更确切地说：这种行为的后果并不立即明显。而后果就是，Gen2/Gen0的触发比例开始增加。也就是说，Gen0-Gen1存在的优势丧失了。在非常密集的流量下，一切都变成了连续的Gen2。

因此，我们可以轻松地在实体生命周期概念上再增加一层虚拟化。例如，这样：

```csharp
var instance = Heap<Foo>.Create();
instance.DanceDance();
Heap<Foo>.Return(instance)
// instance不能再使用了，因为我们已经释放了内存
```

我们的感知发生了什么变化？通过联想思维。如果之前我们调用`new Foo()`，对*我们*来说意味着“在Gen0堆中创建一个Foo类型的对象”，那么现在调用`Heap<Foo>.Create()`引入了一个新的构造：“在对象堆中创建一个Foo类型的对象”。并且“将Foo类型的对象返回到堆中”。

你同意吗？有趣吧？程序代码可以是任何样子的。*我们*赋予它意义。就像我们希望它被*正确*理解一样。因为如果把所有这些都换个名字：

```csharp
var instance = FreeObjectsQueue<Foo>.Dequeue();
instance.DanceDance();
FreeObjectsQueue<Foo>.Enqueue(instance)
```

我们就不会把它看作是堆了。只是某种封装的队列。如果是这样：

```csharp
var instance = UnfocusedObjects<Foo>.MakeFocus();
instance.DanceDance();
UnfocusedObjects<Foo>.RemoveFocus(instance)
```

尽管从功能角度来看，这完全是相同的，但我们甚至不会开始使用它：名字完全是另一回事。

然而，让我们回到我们想要使用的例子：

```csharp
var instance = Heap<Foo>.Create();
instance.DanceDance();
Heap<Foo>.Return(instance)
```

让我们思考，我们如何能实现它：以便可以分配内存并将其返回到堆中，以便稍后再次使用。实际上，当我第一次写下这个实现时，甚至有些怀疑，我是否有权将**这个**称为堆：

```csharp
public static class Heap<T> where T : class, new()
{
    private ConcurrentQueue<T> objects;
    private const MinPoolSize = 32;

    static Heap()
    {
        objects = new ConcurrentQueue<T>(MinPoolSize);
    }

    public static T Create()
    {
        if(objects.TryDeqeue(out var instance))
        {
            return instance;
        }
        return new T();
    }

    public static void Return(T instance) => objects.Enqeue(instance);
}
```

它非常简单：甚至是原始的。这里没有数组，没有对象的标记...也没有根据大小分段的空闲区域列表...这里什么都没有。只是一个队列。斯坦尼斯拉夫？你这是...为了队列而写章节吗？*眼神飘忽*。嗯，从某种意义上说，是的。实际上，栈的工作速度更快。而且，用一些技巧可以更快。但是..等等，不要急着关闭章节！很快你就会理解并喜欢这小小的代码集。

你对`var instance = Heap<Foo>.Create()`构造的态度改变了吗？是否觉得“太原始了”？如果是，那完全是白费心机！我们在这里看到的，只是对一个类型的对象的管理。没有必要保存占用区域的列表：对象在用户手中。但我们获得了一系列优势：

- 我们无论如何都会得到一个对象：即使池中根本没有对象；
- 如果池中有对象，我们会得到它们：进行重用；
- 我们可以预先创建许多对象并将它们放入池中，以便它们在第二代中紧密排列；
- 如果出于某种原因我们没有将对象返回到池中...没关系：GC会回收它。此类泄漏很容易在`dotMemory`中追踪。

根据最后一点，我们可以得出结论，转向`Heap<T>.Create()`将会相当容易：可以首先替换所有的`new T()`为`Heap<T>.Create()`，然后作为第一步，在你认为必要的地方写上`Heap<T>.Return(instance)`。之后 —— 启动`dotMemory`并检查你类型的对象的“泄漏”：对象流量。找到这样的“泄漏”后，决定：它们真的重要吗？影响大局吗？如果是，就去解决它们，插入`Heap<T>.Return(instance)`到合适的地方。例如，在`Dispose()`方法中。

[>]: 这也是一个有趣的观察。现在，“泄漏”这个词不仅意味着某个对象在内存中的非计划保留，还意味着对象非计划地进入垃圾回收器。

## 关于集合的几句话

在更深入地探讨之前，我想简单谈谈集合。集合的主要问题在于，它们创建的主要内存流量不是来自集合类型本身，而是来自它们包含的内容。换句话说，主要的流量不是来自`List<T>`类型，而是来自构成`List<T>`的`T[]`数组。当然，解决方案将在于替换为具有相同API的其他集合。外部看起来相同，但内部是基于数组池化和集合`Dispose`以释放不再需要的数组的完全不同的算法。

## 引言的结尾

优化代码是一个非常创造性和吸引人的任务。这个任务如此吸引人，以至于有时很难停下来画上句号。总是看到“另一个时刻”，最终过程变成了一场极其吸引人的追求。不仅如此，当你从优化转向微优化（从“不是500毫秒，而是200毫秒”到“不是100毫秒，而是90毫秒”）时，你开始注意到，即使是这些微小的优化也可以增加性能的倍数。

简单的例子：
- 第一次优化将操作时间从500毫秒缩短到150毫秒（500/150= x3.33）。感觉像是“很多”；
- 第二次缩短到100毫秒（500/100 = x5）。感觉可能已经足够了；
- 第三次缩短到80毫秒（500/80 = x6.25）。优化变得困难，感觉我们在做额外的工作：毕竟投入了很多努力。但惊讶地发现倍数增加了；
- 第四次缩短到65毫秒（500/65 = x7.69）。回头看，“如果我们在第二步就停下来，会失去很多”。

看到第二个较大的优化，我们本可以在那个阶段就停下来。因为之后遇到的将是时间优化上的小数字，甚至不值得考虑。然而，一切都极度依赖于上下文。有时在第二阶段决定停下来确实是合理的。但有时，“走到底”的决定是合理的。一个简单的分歧示例：如果这段代码非常频繁地被调用。集合方法，字符串操作。例如，如果服务的任务是解析某些文档，那么如果考虑到网络工作的速度倍数也会增加，而不仅仅是解析库的速度倍数，那么“优化到底”可能是合理的。如果网络开始落后，那么可以考虑（如果这很重要）优化网络工作。从REST API转向二进制交换。有时甚至转向UDP。还应该考虑，你是否已经将数据通道加载到最大可能的极限？是否值得将数据解析和网络接收分开？用一个线程接收，另一个或两个线程解析？总之，问题很多。在每个阶段都可以做得更快。

而且，越是思考这些任务，就越会注意到平台中存在一些人为的限制。其中最明显的是不可替代的`ThreadPool`。问题在于，标准的处理速度非常慢，人为地降低了应用程序的性能。而且没人注意到：对平台的信任更高。

总的来说，当我开始进行性能分析时，我意识到最大的坏处是流行的库。它们很流行很多时候只是因为“很久以前就出现了”。人们习惯了它们，新的不被考虑引入（例如，因为它们缺少某些功能或因为其他库的制造商不支持它们），结果就是程序承受了不必要的高负载。就因为库是这样写的。

你可能会说：哦，当然，全是谎言。而我给你一个反例。请求-响应服务。与MongoDB交互。服务代码的运行时间只占20%。为什么？因为从MongoDB中取出了相当大的文档，解析它们，交给服务代码处理。MongoDB传输协议的解析库，`BSON`格式，每秒生成高达100MB的流量。只是因为写得不好。加上`Newtonsoft.JSON`。加上Mongo驱动本身对网络的不优化处理。结果，根据`dotMemory`的数据，仅GC Wait就占用了将近50%的时间。10%是网络，20%是服务代码本身，以及30%是BSON解析代码，它产生了40-50%的GC Wait流量。换句话说，解析代码不是工作30%，而是70-80%的时间。这成为了重写这个库的原因。顺便说一下，它是MongoDB官方驱动的一部分。