## 为对象分配内存

>{.big-quote} 课程适应过程中

我们刚刚从鸟瞰视角讨论了GC。现在我们将深入细节。首先，我想谈谈内存分配算法。

.NET开发者对内存管理的兴趣主要来自两个基本过程：第一个是分配内存，第二个是释放内存。我们现在将讨论内存分配。

从处理器的角度来看，内存看起来更复杂一些。如果谈论内存管理的架构，我会说它被分为几层。我们看到的第一层，.NET层，相当复杂，但它是高级的。也就是说，它无论如何都依赖于其他东西，即Windows的内存管理层，而这又运行在某种处理器上。处理器以自己的方式解释这些内存。因此，我们实际上有三层内存管理。

从处理器的角度看，内存是条板，物理内存，RAM。我们安装了多少条板，它就看到多少。但我们知道，Windows系统中运行的每个进程都是隔离的。除了自己，它什么也看不到。有自己的进程，winapi，除此之外什么也没有。Word看不到Excel。Excel看不到计算器。它们都是完全隔离的。因为在Intel架构上实现了内存虚拟化。

它是如何工作的。有我们看不到的全局描述符表，有被发送到某处的局部描述符表。所有这些一起指向页面帧。

任何进程都有一定的内存范围，从零到比如说在x32系统上的4GB，以及在x64系统上的条件性无限。这是虚拟内存的范围。处理器为特定程序创建了一个虚拟的部分，这个部分只包含该程序。这个区域被分成了多个页面：每个页面4KB大小。每一个页面都表示该处的内存要么存在，要么不存在，即在这个位置物理上完全没有内存。有地址，但那里没有内存。这种情况出现在，例如当一个4GB的内存条被插入主板，而我们运行了一百个进程，并且是32位的Windows系统时。这意味着每个程序都有4GB的内存，但它们彼此是隔离的。

如何将4GB分给一百个人，每人获得4GB？做不到。这意味着在四千兆字节的区域内，每个程序都有一些没有内存的地方，那里只分配了地址片段。但在某些地方有内存，并且它被映射到物理内存条上。如果没有映射 - 就没有内存。如果尝试访问那里，试图读取一些东西，你会得到的不是零，而是AccessViolationException。这个异常表明你试图操作一个不存在的片段，或者你没有权限操作的片段。在这个层面上，异常不做区分。

同样的原理也适用于Wap。（参见幻灯片06:30）。图像中以柱状图形式突出显示了进程。白噪声的地方是分配并填充了内存的地方。而有空隙的地方则没有内存。分配的区域可以映射到物理内存或硬盘上。

例如，如果一个程序分配了很多内存但没有使用，而相邻的程序需要内存，同时内存条较小，那么Windows会将未使用的内存卸载到硬盘上，并将这部分内存分配给其他人。

那么，在我们的.NET应用程序中，一部分内存被使用了，而另一部分没有被使用。我们怎样才能查看这一点呢？可以运行一个工具，比如有Procmon。它们可以显示应用程序是如何消耗内存的。你可以看到一些行，这些正是被分配的区域。第一列是区域的地址，第二列指示堆(heap)，第三列是区域的大小。还有一个列是committed。这是什么意思呢？如果程序决定它需要一个堆，并尝试确定要创建哪一个。它会为堆预留内存，然后决定提交(commit)一部分。虚拟地址空间被分成了页面。页面有三种状态。第一种是空闲页面，上面什么都没有。可以随意拿来使用。第二种状态是页面被预留。这意味着程序的某个部分为自己预留了这个页面，但那里仍然没有内存，它不存在。但页面是为将来的需要预留的。这样做是为了确保在分配的堆中，其他人不能在中间随意分配东西。

你可能会觉得，作为自己应用程序的主人，你想怎样分配内存就怎样分配。实际上并非如此。如果你纯粹在.NET中，那可能是的。但通常来说，.NET经常调用Managed code，而Managed code也需要内存。它不会在.NET的堆中分配内存——SOH和LOH。它对它们一无所知。

它会在自己的堆中分配内存。如果是C++，那就是C++运行时库。但那里有自己的堆构建机制。这意味着你并不能完全控制分配给你的虚拟地址范围。为了保护自己，你会立即预留地址空间，并在其中开始分配内存——提交它，使其存在，以便可以写入东西。

在第11:50的幻灯片上，可以看到有空闲的位置，还有一个部分预留、部分已提交的连续区域。这个位置可能在内存中，或者位于硬盘上，因为它已经很长时间没有被使用了。如果你访问的是位于硬盘上的数据块，那么它会自动加载并变成内存中的数据块。但你现在不需要知道这些。

了解了这些之后，我们来分析`var x = new A();`是如何工作的。

回到基础知识，这是我们通常在面试时会讲解的内容。当我们与程序员交流时，他们会问我们一切是如何工作的。我们解释说，有三代。内存是如何分配的？指针指向一个空闲区域，当执行new操作时，我们将这个地址分配出去，并将指针移动到分配的块的大小位置。当GC（垃圾收集）发生时，堆会被压缩，这个指针就会提前移动，因为堆已经被压缩了。大致就是这样发生的。在13:31的幻灯片上，我们有一个已提交的部分 - 在垂直线的左侧。这部分内存是实际存在的。线的右侧是为堆保留的部分，但它目前还不存在。接下来，我们需要回忆一下所谓的分配上下文（allocation context）。这是一个滑动窗口，在这个窗口内，内存管理器目前正在为对象分配内存。而在它内部，我们有指向空闲空间开始位置的指针。左侧已经开始有对象了。

当进行 new A() 操作时，我们会记住这个地址，在那里放置对象，并移动空闲空间开始的地址，将地址赋给变量 x。我们的代码大致如下（见幻灯片 14:39）。我们有一个 Allocate() 方法，我们向它请求了一定量的内存。它会检查我们是否有未来的空闲地址（起始地址加上该 amount）。如果超过了堆大小，我们就无法分配新的内存，于是我们会抛出 OutOfMemoryException。否则，我们就会把这个地址交给请求方，更新整个内存范围，以确保没有多余的数据。

但可能会出现分配上下文已经用尽的情况。那么就会错过这个上下文。在这种情况下该如何行动？分配器可以采取两种方式。第一种是尽可能少地分配，第二种是分配一定量到某个最大值。这个大小可以从 1 到 8KB 不等。它的选择取决于内存分配的频率。如果在某个线程上分配了大量内存，那么分配一小块内存就没有任何意义。也就是说，分配上下文会根据当前的请求进行扩展。

但还存在多线程的情况。如果有多线程，可能会出现多个线程同时开始请求内存分配。这意味着，我们的 new 操作符必须是线程安全的，也就意味着它会变慢。它本身是快速的，但如果它在没有与其他线程竞争的情况下分配，那么它的工作就会变得不合理地慢。为了使 new 成为线程安全的，每个线程需要在自己的某个地方分配内存。因此，在 .NET 中，每个线程都有自己的一个分配上下文。

由此我们可以得出另一个结论 - 不应该创建太多不必要的线程。这样做会因此而产生一个非常大的零代堆。

所以，我们已经有很多流存在，每个流都会有所输出。而且我们还有三代。这就意味着，第零代在输出的同时开始增长，这是因为我们的流数量在增加。这是不好的。

让我们来看看空闲区域列表的想法。

如果我们谈论的是经典的做法，像在所有地方一样，.NET的堆(heap)设置也不例外。当进行垃圾收集的清扫(sweep collection)而不是压缩堆时，我们会得到空闲区域。我们需要以某种方式管理它们。

有两种管理空闲区域的算法。第一种是最佳匹配(best-fit)。当分配内存时，从所有空闲区域中选择一个大小相同或最接近请求大小的区域。这就是最佳匹配。

当我们使用最佳匹配时，我们需要找到最佳区域。我们遍历所有区域，并记住我们经过的区域。这是一种线性搜索，我们的区域可能在最后。但是，这样我们得到的内存碎片最小，这很好。第二种算法是首次匹配(first-fit)。这是另一种选择。我们向前遍历列表，取第一个适合的区域。它的大小可能相同，或者更大，甚至是所需大小的许多倍。这种方法很快，但可能会导致内存高度碎片化。在.NET中，这些方法的混合被用来通过桶(bucket)组织空闲区域列表。每一代都有自己的桶列表。它们按大小从小到大对内存进行分组。每个桶指向一个空闲区域的单链表。如果我们往下看，从头部到一个空闲区域，然后沿着单链表继续前进，列举出属于该桶的所有空闲区域。记住，它们是按大小组织的。在这个桶里，区域有特定的大小范围。在下一个桶里，将有它们自己的范围。

桶（Бакет）是一种首次适配（first-fit）方法，在众多桶中选择第一个适合的，进入这个桶内部，然后通过单链表进行最佳适配（best-fit）搜索。通过这种方式，我们可以实现非常好的优化。

什么是桶（Бакеты）？这张表格（见幻灯片22:05）为我们揭示了答案。这里我们回顾一下SOH和LOH之间的区别：LOH仅通过扫描回收（sweep collection）原则组织，堆压缩只按需发生。LOH中的堆压缩不会自动触发。而SOH中则混合使用了这些策略。

我们来看看LOH和第二代，后者是最大的。基于这点，我们可以轻松理解表格的内容。第零代和第一代只有1个桶，因为在第零代和第一代中，扫描过程中不会形成足够大的空闲区块来放置新的上下文。我们在这里不需要桶的功能，因此只有一个桶。

而在第二代，可能包含了数千兆字节的小对象，在LOH中，桶已经存在，通过之前描述的结构，内存得以组织。

那么在这种情况下，内存是如何被分配的呢？首先，我们扫描桶，寻找第一个大小合适的区块。当我们选择了一个桶，就通过单链表寻找最佳匹配——即大小最适合我们需求的那个。但有一个特点。可能会出现我们请求的空间不多，而现有的区块太大的情况。在这种情况下，我们将分配所需的空间，而剩余的部分则返回到空闲区块列表中。

那么，我们找到了所需的区块。在这个地方，有一个对象的仿真。第一个字段是undo字段。这是一个已经释放的区块，那里曾经放置了一个对象或一组对象。因此，第一个字段是aSyncBlockIndex，然后是虚拟方法表，然后是数据。当这个区块变成了一个空闲内存区块时，第一个字段变成了undo操作。当我们解除这个区块的链接并在undo操作中保存对下一个区块的引用时，以便在出现问题时可以撤销。

接下来是空闲区块的虚拟方法表，以便GC能够理解它正在处理什么，以及size - 空闲区块的大小。

在这之后，我们设置aSyncBlockIndex。虚拟方法表变成了所需的那个，并且调用了构造函数。就是这样。这就是内存分配的工作方式。

## 在SOH中的内存分配

这意味着，为了分配内存，首先执行最简单的方法。如果对象适合于allocation context，我们就分配并提供它。这是最快的方法。我们立即完成，没有任何额外的操作：进入然后退出，移动指针对我们来说不费劲。

如果不适合于context，那么就会有第一个复杂化。需要增加context的大小。为了增加，我们使用更高级的方法，它位于JIT_NEW helper中。

我们尝试在ephemeral段中找到未使用的部分。当我们的allocation context用完时，我们必须将其移动到某处。这很昂贵。因此，我们首先尝试增加它，扩大它。如果这做不到，那么就需要移动它。

我们需要将它移动到哪里，以及我们有哪些数据可以用于这个目的？

需要通过桶在列表中寻找一个适合我们context的空闲区块。如果有这样的区块，我们就将它移动到那里，并尝试用第一种方法在那里分配内存。

如果成功了 - 那就太好了。如果没成功，我们尝试提交更多的预留内存：将垂直线向右移动。虽然位置已经预留，但那里还没有实际的内存。我们需要扩展堆，并且我们提交内存。我们不会立即这样做，因为提交操作是一个相当耗时的过程，和预留一样。它可能需要上百毫秒。这是因为要执行它，需要调用Windows。而操作系统对其内部的内容极度不信任。它为我们隔离出一个沙箱环境，当我们调用winapi方法时，我们不仅仅是调用它，而是以提升的权限级别调用。为了安全地执行此操作，Windows需要将从应用层调用的方法帧复制到内核层，以避免意外捕获到外部的感染数据。然后winapi函数执行并返回。在这一刻，会进行栈的部分反向复制，并从内核空间转回到用户空间。整个操作耗时很长，因此GC尽可能地利用当前空间。在每个阶段，它都会进行第零代GC：如果可以压缩一些东西，可能分配上下文会再次增长。当上下文用尽时，GC尝试向右扩展，但如果那里已经有东西了，就需要寻找空闲区域。如果不行，就会进行垃圾收集，可能会出现空闲区域，新数据就能够被放置其中。当一切都不行，所有空间都被占用时，就不得不继续提交内存。如果内存用尽了，就会抛出OutOfMemoryException异常。

## 大对象堆的内存分配

在大型对象的热潮中，我们尝试寻找未使用的内存，对每个LOH的短暂段重复此过程，因为根据.NET平台的工作模式，这里可能有多个这样的段。由于LOH默认没有堆压缩，所以这里的内存管理被简化了。堆压缩是一个非常重的操作，需要大量的计算过程。但在LOH中，这个操作只是按需进行，这意味着程序员根据自己程序的算法工作知识，决定了此时他准备花费未知的时间来压缩巨大的空间。因此，可以大大简化与LOH工作相关的算法。

对于每个短暂段，我们在空闲列表中寻找内存区域，如果找不到就尝试增加。如果无法增加 - 尝试提交保留的部分。下一步，启动GC，可能多次。如果完全不行 - 触发OutOfMemoryException。在这种方法中，没有“压缩”这个词，我们走的是简单的路。

多线程。有一个概念叫做堆平衡。例如，GC在服务器模式下运行。这意味着它有几个SOH和LOH，这些对分配给特定的处理器核心。每个核心有自己的一对堆和自己的线程。

假设某个核心的平衡被打破了。它开始分配太多的内存，不再适合当前的段。让我们考虑在这种情况下内存管理系统可以做什么。

它可能会认为，如果这个核心进行非常密集的分配，那么可以将上下文转移到相邻的核心并在那里进行分配。一个核心空闲，而另一个核心被最大限度地利用。这将帮助避免诸如内存提交之类的昂贵操作。但是，当上下文改变时，与这个区域一起，线程也被转移到另一个核心。

这不仅仅是因为内存用尽了。还有其他原因。每个处理器都有一个核心缓存。当应用程序在某个内存区域工作时，整个区域都会被加载到这个缓存中。当你开始处理另一个区域并且没有命中缓存时，就需要将另一个内存区域加载到缓存中。如果来回切换，就会出现最糟糕的情况。一切都会变得非常非常慢。

当当前的核心分配上下文用尽时，如果相邻的核心此时没有活动，将上下文转移到那里比分配新的内存块更简单，那么它就不得不将当前线程一起转移过去。现在它将在另一个内存范围上工作。它需要将另一个内存范围加载到它的缓存中。因此，当前线程随着上下文一起移动。

从这里我们可以得出什么结论。首先，需要记住内存是如何被分配的。其次，为了优化GC（垃圾收集器）的工作，需要理解你将需要多少特定类型的对象。在调用new之后，填充了内存，你的算法就完成了。然后，比如在循环中，你又创建了另一个这种类型的对象。这是不好的。算法需要一些时间来执行，在此期间，可能在并行线程中进行了其他分配。并且在同一个算法中，你可能会分配其他内存。因此，你按类型分段了内存。在GC期间，你需要第一类型的对象作为第零代对象，这些对象会快速消失。但在算法中，你分配了永久对象。GC被迫进行堆压缩阶段，因为这些快速消失的对象留下了小块的空闲内存，无法再放置任何东西。否则，GC可以仅通过普通的sweep来处理：如果该区域足够大，它就会被加入到空闲区域列表中。

如果有一个需要执行一万次迭代的算法，其中需要A类型的对象，最好是一开始就批量分配这些对象，然后再使用它们。这样，当垃圾回收（GC）工作时，它会处理一个巨大的区域，这个区域是这些对象被分配的地方。然后，它会将这整个区域归还到空闲区域列表中。如果你的算法每次只需要一个A类型对象的实例，那么应该重用它，通过创建一个init方法来代替构造函数。这样做的结果是，你根本不会造成内存碎片，而是一直在一个对象上工作。

如果你同时需要一百个对象，就创建一个对象池，并从中取出对象来使用，这样可以避免在算法内部使用短生命周期的对象来造成内存碎片，避免进行长时间的堆压缩。

第一本书不久前出版。它是由Konrad Kokosa撰写的，是一本关于内存管理的书，共一千页。当我第一次拿到这本书时，我期待的是些许不同的内容。书的厚度让我感到震惊。实际上，作者做得很好。他为不同水平的读者编写了这本书。这意味着，你可以剔除所有不必要的内容。例如，处理器的内存管理级别、Windows、一些便于诊断使用的工具列表 - 如果你只是想了解内存管理，那么可以只读这本书的后半部分。书的前半部分只是为后半部分做准备。而后半部分正是关于内存管理的。这部分用了非常简单的语言，不断地引用前面的章节。

如果将这本书压缩，可以得到大约300页。这已经是一个可接受的长度，是可能阅读的。

第二本书 - 《深入.NET内存管理》- 对我来说已经是经典了。它没有被翻译成俄语，只能通过Red Gate网站获取，这个网站提供各种重构工具和数据库操作工具。他们也有一个内存分析工具，因此他们不得不研究内存是如何工作的。书中以非常简洁的风格描述了这一切，足以在面试中给人留下深刻印象。大约有200页。还有我的书。

你有什么问题吗？

- ....（录音中听不到问题）

- 看来是需要的。关于如何正确下载这些内容，以避免浪费并确保一切方便，纳塔利亚会部分回答这个问题。无论如何都需要使用相同的数组，使用已经出现的池。可以编写自己的或使用新出现的池。纳塔利亚会告诉你如何熟练地使用它们。

- ....（录音中听不到问题）

- 数组是一个引用数组。你不能创建一个图片数组。是图片的引用数组。

- ....（录音中听不到问题）

- 把它用作GUI的键。

- ....（录音中听不到问题）

- 这个问题是关于在不考虑特定核心的内存使用情况下，将线程从一个核心转移到另一个核心的逻辑性。在这种情况下，分类是什么。

我们有第一个核心。它在做一些事情，它后面跟着两个线程。当它从第二个核心转移过来时，在第一个核心内一切正常：它如何处理自己的内存，就如何工作。这是第一个场景。第二个场景。从第二个转移到第一个的线程。当我们这样做时，我们不是随便这样做，而是因为它在那个时刻正在积极分配内存。这一切都是基于统计数据来做的。显然，统计数据得出的结论是：应用程序更频繁地操作它刚刚分配的内存。

- ....（录音中听不到问题）

- 在目标核心上？

•	... (问题未录音)
•	不会有任何问题，一切都会好的。他们在计算些什么，不分配内存，不需要上下文。第一个核心有一对堆，它们还会留在那里。它们位于处理器缓存中。当一个线程从另一个核心迁移过来并开始分配时，缓存不会受到影响。工作也是同样的情况。

•	... (问题未录音)

- 可能情况比较复杂。但在我们目前能够理解的层面上，解释就是这样的。

- ...(问题未录音)

•	在哪里可以看到Linux的运行情况？如果你想看看Linux中所有相同的过程是如何发生的，可以查看CoreCLR的仓库，在文档部分有botr - 运行时之书。这是一本网页书籍，核心开发者在这里编写文档，说明它是如何工作的。这是第一种方式。第二种方式是查看源代码。但如果你不想被吓到，我不建议这么做。第三种方式是进入运行时之书，看看谁在那里写文章并联系他们。

•	... (问题未录音)

- 有.NET标准，有不同的平台。如何编写代码以确保在所有地方都能良好运行。答案是这样的。.NET Core和.NET framework都是基于RED JIT 57:05运行的。这是一种JIT编译和GC系统。它们的代码基础是一样的。差异很小。例如，在卡片桌方法中有一些差异。在Windows中，基于触发器和内存页自动设置标志，如Bundle Table。在Linux中，这将是手动设置。但这不应该让你担心，这是一个低级细节，不会影响任何事情。主要层面是统一的，我还没有遇到其他特别之处。

- ...(问题未录音)

- 是的，这些文献已经足够了。

-... (问题未录音)

- 这里有一个平衡。关于缓存的问题。

缓存是一种集中式存储。在这个意义上，所有指向较年轻一代的引用都将被紧密地存储在一起——这是关键。在这种情况下，有百分之百的可能性，一个32位的机器字能够覆盖整个缓存。在这里，引用的数量不重要，只会设置一个单位。

- ...（录音中听不到问题）

- 如果它们存储在一起，那就好。如果你的第二代很大，并且你在整个一代中随机地不断设置指向较年轻一代的引用，那就是一个糟糕的情况。这是一个罕见的情况。因此才设计了卡片桌。应用程序将从较老一代随机地在整个内存中设置指向较年轻一代的引用。如果发生这种情况，那就非常糟糕，因为它将不得不检查数兆字节的对象，看看其中哪些字段指向较年轻一代。

所有指向较年轻一代的地方都应该尽可能地被分组。

- ...（录音中听不到问题）

- 通过分组指向较年轻一代的引用位置，你简化了GC的工作。反之，则它在遇到带有一个单位的卡片时，被迫检查一个巨大的内存范围，而这些内存除了一个字段外都不指向较年轻一代。稀疏地引用较年轻一代是最糟糕的情况。如果把所有这些都放在一起，那么它只需检查一次卡片桌。缓存是好的。

- ...（录音中听不到问题）

- 如果有很多缓存，那么很可能会有几个卡片桌。当你有很多未缓存的内容，只是稀疏的内存，并且有一些单独的引用不断被设置时，这是不好的。- ...（录音中听不到问题）

- Async/await 根本不需要知道它在哪些线程上执行。这只是语法糖。关于语法糖，在后续的报告中得出的结论是，在应用程序的高负载部分，不能使用它。因为语法糖经常会在程序代码中看不到的地方产生对象分配，这将伴随着内存流量、GC（垃圾收集）流量。因此，如果你有工作负载较高的内存部分，那里就必须放弃使用语法糖。

- ...（录音中未听到问题）

- 这正是语法糖的结果。因为 async/await，这毕竟是帮助我们方便地编写代码。需要确保在高负载代码中，当分配某些东西时，它发生在一个特定的、明确的地方，不使用额外的结构。这样你就能控制情况。当你使用 async/await、forEach、lambda 时，你开始进行额外的分配。这样就产生了额外的流量。这很方便，但需要适度。